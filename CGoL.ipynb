{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "from torch import functional as F\n",
    "from typing import Callable, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class GameRule(torch.nn.Module):\n",
    "    def __init__(self, zero_kernel, one_kernel, zero_bias, one_bias, activation_zero, activation_one):\n",
    "        super().__init__()\n",
    "        self.zero_kernel = zero_kernel.unsqueeze(0).unsqueeze(0).to(device)\n",
    "        self.one_kernel = one_kernel.unsqueeze(0).unsqueeze(0).to(device)\n",
    "        self.zero_bias = torch.tensor([zero_bias]).to(device)\n",
    "        self.one_bias = torch.tensor([one_bias]).to(device)\n",
    "        self.activation_zero = activation_zero\n",
    "        self.activation_one = activation_one\n",
    "\n",
    "    def forward(self, input):\n",
    "        conv0 = torch.conv2d(input=input, weight=self.zero_kernel, bias=self.zero_bias, padding='same', stride=1)\n",
    "        conv1 = torch.conv2d(input=input, weight=self.one_kernel, bias=self.one_bias, padding='same', stride=1)\n",
    "        return (input > 0.5) * self.activation_one(conv1) + (input < 0.5) * self.activation_zero(conv0)"
   ],
   "id": "6765f50f9b7e0be7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_baseline_rule() -> GameRule:\n",
    "    def baseline_activation1(board: torch.Tensor) -> torch.Tensor:\n",
    "        mask = (board >= 2) * (board <= 3)\n",
    "        return mask.to(torch.float32)\n",
    "    def baseline_activation0(board: torch.Tensor) -> torch.Tensor:\n",
    "        mask = (board - 3).abs() < 1e-5\n",
    "        return mask.to(torch.float32)\n",
    "    kernel = torch.tensor([[1, 1, 1], [1, 0, 1], [1, 1, 1]]).to(torch.float32)\n",
    "    return GameRule(kernel, kernel, 0., 0., baseline_activation0, baseline_activation1)"
   ],
   "id": "e5c6b7b3dbbc296",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ipywidgets import HTML\n",
    "\n",
    "\n",
    "def simulate(initial_state: torch.Tensor,\n",
    "             rule: GameRule,\n",
    "             interval: int=500,\n",
    "             transitions: int = 20,\n",
    "             visualize: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Animates first n states of CGoL given the initial state\n",
    "\n",
    "    :param initial_state: the initial state of the board\n",
    "    :param rule: the update rule\n",
    "    :param interval: Delay between frames in milliseconds.\n",
    "    :param transitions: Number of transitions to simulate.\n",
    "    :param visualize: If true, visualize the transitions\n",
    "    :return final state of the board\n",
    "    \"\"\"\n",
    "\n",
    "    current_state = initial_state.unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    if visualize:\n",
    "        fig, ax = plt.subplots()\n",
    "        img = ax.imshow(initial_state.numpy(), cmap='jet', vmin=0, vmax=1)  # Set color map and value range\n",
    "        plt.colorbar(img, ax=ax)\n",
    "\n",
    "        def update(frame):\n",
    "            nonlocal current_state\n",
    "            current_state = rule(current_state)\n",
    "            img.set_array(current_state.squeeze().numpy())\n",
    "            return [img]\n",
    "\n",
    "        ani = animation.FuncAnimation(fig, update, frames=transitions, interval=interval, blit=False)\n",
    "        return ani\n",
    "\n",
    "    else:\n",
    "        for _ in range(transitions):\n",
    "            rule(current_state)\n",
    "\n",
    "    return current_state\n"
   ],
   "id": "57609d0139247331",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#%matplotlib notebook\n",
    "simulate(torch.randint(0, 2, (100, 100), dtype=torch.float), get_baseline_rule(), transitions=1000, interval=200)"
   ],
   "id": "acda01e18d9d6d65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Continuous activation\n",
    "Now we wil replace step activation functions with normal distribution. I will adjust new activations to keep the integral of activation functions at the same level. (When integrating over reals, which ofc is not 100% proper)"
   ],
   "id": "7964c4efeb3325a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_continuous_rule() -> GameRule:\n",
    "    def continuous_activation1(board: torch.Tensor) -> torch.Tensor:\n",
    "        dist = torch.distributions.normal.Normal(2, 1.25)\n",
    "        return torch.exp(dist.log_prob(torch.Tensor(board))) * 2\n",
    "    def continuous_activation0(board: torch.Tensor) -> torch.Tensor:\n",
    "        dist = torch.distributions.normal.Normal(3, 0.25)\n",
    "        return torch.exp(dist.log_prob(torch.Tensor(board))) * 2\n",
    "    kernel = torch.tensor([[1, 1, 1], [1, 0, 1], [1, 1, 1]]).to(torch.float32)\n",
    "    return GameRule(kernel, kernel, 0., 0., continuous_activation0, continuous_activation1)"
   ],
   "id": "454dc30a3e08772e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "simulate(torch.rand((50, 50), dtype=torch.float), get_continuous_rule(), transitions=100, interval=200)",
   "id": "4a9530780b24e4cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I have realised that the transition rules defined above behaves strangely because I let the cell value exceed `1`. In the following section I will fix this. I will leave the improper transition rules for educational purposes.",
   "id": "5d63e03192e3ffa7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "EPSILON = 1e-6\n",
    "def get_continuous_rule_fixed(alpha = 2.5) -> GameRule:\n",
    "    def continuous_activation1(board: torch.Tensor) -> torch.Tensor:\n",
    "        board -= 2.5\n",
    "        board *= alpha\n",
    "        return (torch.sin(board) / abs(board) + EPSILON) ** 2\n",
    "    def continuous_activation0(board: torch.Tensor) -> torch.Tensor:\n",
    "        board -= 3\n",
    "        board *= alpha\n",
    "        return (torch.sin(board) / abs(board) + EPSILON) ** 2\n",
    "    kernel = torch.tensor([[1, 1, 1], [1, 0, 1], [1, 1, 1]]).to(torch.float32)\n",
    "    return GameRule(kernel, kernel, 0., 0., continuous_activation0, continuous_activation1)"
   ],
   "id": "2e0a312747932157",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Given this formula, I will try to find value of alpha such that expected cell value after first iteration will still be 0.5.",
   "id": "857d57d6ddbe1b11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "simulate(torch.rand((100, 100), dtype=torch.float), get_continuous_rule_fixed(alpha=2.2), transitions=500, interval=200)",
   "id": "d50c74471fec6c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lets try asymmetrical discrete rule:",
   "id": "35d727f2d2b0f2d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_asym_discrete_rule() -> GameRule:\n",
    "    def baseline_activation1(board: torch.Tensor) -> torch.Tensor:\n",
    "        mask = (board >= 2) * (board <= 3)\n",
    "        return mask.to(torch.float32)\n",
    "    def baseline_activation0(board: torch.Tensor) -> torch.Tensor:\n",
    "        mask = (board - 3).abs() < 1e-5\n",
    "        return mask.to(torch.float32)\n",
    "    kernel = torch.tensor([[1, 1, 1], [2, 0, 1], [1, 1, 1]]).to(torch.float32)\n",
    "    return GameRule(kernel, kernel, 0., 0., baseline_activation0, baseline_activation1)"
   ],
   "id": "2a21dba0c182a65d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "simulate(torch.randint(0, 2, (100, 100), dtype=torch.float), get_asym_discrete_rule(), transitions=1000, interval=200)",
   "id": "db5c5843439952fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The rule above creates a lot of simple gliders.",
   "id": "c13f82aaebd5fb41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Continuous asymmetric rule",
   "id": "9a674f512f65fc12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_continuous_asymmetric_rule(alpha = 2.5) -> GameRule:\n",
    "    def continuous_activation1(board: torch.Tensor) -> torch.Tensor:\n",
    "        board -= 2.5\n",
    "        board *= alpha\n",
    "        return (torch.sin(board) / abs(board) + EPSILON) ** 2\n",
    "    def continuous_activation0(board: torch.Tensor) -> torch.Tensor:\n",
    "        board -= 3\n",
    "        board *= alpha\n",
    "        return (torch.sin(board) / abs(board) + EPSILON) ** 2\n",
    "    kernel = torch.tensor([[1.3, 0.8, 0.9], [1, 0, 1], [1, 1, 1]]).to(torch.float32)\n",
    "    return GameRule(kernel, kernel, 0., 0., continuous_activation0, continuous_activation1)"
   ],
   "id": "411cdc05e8f15bca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "simulate(torch.rand((100, 100), dtype=torch.float), get_continuous_asymmetric_rule(alpha=2.2), transitions=200, interval=200)",
   "id": "50f5a40a7ff7c62d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_monoconv_rule():\n",
    "    def activation(board: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.nn.functional.sigmoid(board)\n",
    "    kernel = torch.tensor([[.15, .1, .1], [0.2, 0.7, 0.1], [0.05, 0.12, 0.1]]).to(torch.float32) / 2.\n",
    "    return GameRule(kernel, kernel, 0., 0., activation, activation)"
   ],
   "id": "14a8a9f1630c9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "simulate(torch.rand((100, 100), dtype=torch.float), get_monoconv_rule(), transitions=200, interval=200)",
   "id": "b49dee4436176fe0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sine rule",
   "id": "cee9d7103a4f5863"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_sine_rule(delta: float = 0.5) -> GameRule:\n",
    "    def activation(board: torch.Tensor) -> torch.Tensor:\n",
    "        return (torch.sin(board) + 1) / 2\n",
    "    kernel = torch.tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]).to(torch.float32) * delta\n",
    "    return GameRule(kernel, kernel, 0., 0., activation, activation)\n",
    "\n",
    "def get_cosine_rule(delta: float = 0.5) -> GameRule:\n",
    "    def activation(board: torch.Tensor) -> torch.Tensor:\n",
    "        return (torch.cos(board) + 1) / 2\n",
    "    kernel = torch.tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]).to(torch.float32) * delta\n",
    "    return GameRule(kernel, kernel, 0., 0., activation, activation)"
   ],
   "id": "fbc62a3bee42d9a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "simulate(torch.rand((100, 100), dtype=torch.float) / 1000., get_sine_rule(delta=0.174), transitions=100, interval=200)",
   "id": "313a5bc79e35f0f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "simulate(torch.rand((100, 100), dtype=torch.float), get_cosine_rule(), transitions=200, interval=200)",
   "id": "21554c76177f19a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rule_converges(rule: GameRule, trials: int, steps: int = 100, board_size: Tuple[int, int] = (100, 100), look_back: int = 1) -> float:\n",
    "    attempts_converged = 0\n",
    "    boards = torch.rand((trials, *board_size))\n",
    "    last_steps = []\n",
    "    for i in range(steps):\n",
    "        if i >= steps - look_back:\n",
    "            last_steps.append(boards.clone())\n",
    "        boards = rule(boards)\n",
    "\n",
    "    for i, b in enumerate(boards):\n",
    "        for copy in last_steps:\n",
    "            if torch.isclose(b, copy[i]):\n",
    "                attempts_converged += 1\n",
    "                break\n",
    "\n",
    "    return attempts_converged / trials\n"
   ],
   "id": "c655254f7e119299",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
